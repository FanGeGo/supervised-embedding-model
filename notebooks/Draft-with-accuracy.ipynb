{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "def score(context, response):\n",
    "    return random.random()\n",
    "\n",
    "\n",
    "def best_response(context, candidates):\n",
    "    index = np.argmax([score(context, response) for response in candidates])\n",
    "    return candidates[index]\n",
    "\n",
    "\n",
    "def parse_dialogs(filename):\n",
    "    dialogs = []\n",
    "    with open(filename, 'r') as f:\n",
    "        dialog = []\n",
    "        for line in f:\n",
    "            if line.strip() == '':\n",
    "                dialogs.append(dialog)\n",
    "                dialog = []\n",
    "            else:\n",
    "                user_utt, bot_utt = line.strip().split('\\t')\n",
    "                utt_num = user_utt.split(' ')[0]\n",
    "                user_utt = ' '.join(user_utt.split(' ')[1:])\n",
    "                dialog.append((utt_num, user_utt, bot_utt))\n",
    "    return dialogs\n",
    "\n",
    "\n",
    "def parse_candidates(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return [' '.join(line.strip().split(' ')[1:]) for line in f]            \n",
    "\n",
    "    \n",
    "def responses_accuracy(dialogs, candidates):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for dialog in dialogs:\n",
    "        for _, user_utt, bot_utt in dialog:\n",
    "            count += 1\n",
    "            context = user_utt\n",
    "            response = best_response(context, candidates)\n",
    "            if response == bot_utt:\n",
    "                correct += 1\n",
    "    return correct / count, correct, count\n",
    "\n",
    "\n",
    "def build_vocab_to_ind_map(dialogs):\n",
    "    vocab = set()\n",
    "    for d in dialogs:\n",
    "        for _, user_utt, bot_utt in d:\n",
    "            vocab = vocab.union(user_utt.split(' ') + bot_utt.split(' '))\n",
    "    vocab = sorted(list(vocab))\n",
    "    \n",
    "    cntr = 0\n",
    "    vocab_ind_map = {}\n",
    "    for w in vocab:\n",
    "        vocab_ind_map[w] = cntr\n",
    "        cntr += 1\n",
    "    return vocab_ind_map\n",
    "\n",
    "\n",
    "def build_vec(vocab_ind_map, utt):\n",
    "    vocab_len = len(vocab_ind_map.keys())\n",
    "    vec = np.zeros((vocab_len, 1))\n",
    "    for w in utt.split(' '):\n",
    "        try:\n",
    "            vec[vocab_ind_map[w]] += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return vec\n",
    "\n",
    "\n",
    "def get_vec_set(dialogs, vocab_ind_map):\n",
    "    vec_set = []\n",
    "    for d in dialogs:\n",
    "        for _, user_utt, bot_utt in d:\n",
    "            x = build_vec(vocab_ind_map, user_utt)\n",
    "            y = build_vec(vocab_ind_map, bot_utt)\n",
    "            vec_set.append([x, y])\n",
    "    return vec_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_set_task1_dialogs = parse_dialogs('dataset/dialog-bAbI-tasks/dialog-babi-task1-API-calls-trn.txt')\n",
    "dev_set_task1_dialogs = parse_dialogs('dataset/dialog-bAbI-tasks/dialog-babi-task1-API-calls-dev.txt')\n",
    "candidates = parse_candidates('dataset/dialog-bAbI-tasks/dialog-babi-candidates.txt')\n",
    "vocab_to_ind_map = build_vocab_to_ind_map(train_set_task1_dialogs)\n",
    "vec_set = get_vec_set(train_set_task1_dialogs, vocab_to_ind_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "D = 32\n",
    "V = len(vocab_to_ind_map)\n",
    "\n",
    "context = tf.placeholder(dtype=tf.float32, name='Context', shape=[V, 1])\n",
    "response = tf.placeholder(dtype=tf.float32, name='Response', shape=[V, 1])\n",
    "f_neg = tf.placeholder(dtype=tf.float32, name='f_neg', shape=())\n",
    "A_var = tf.Variable(initial_value=tf.truncated_normal(shape=[D, V], stddev= 1 / math.sqrt(D)))\n",
    "B_var = tf.Variable(initial_value=tf.truncated_normal(shape=[D, V], stddev= 1 / math.sqrt(D)))\n",
    "\n",
    "resp_mult = tf.matmul(B_var, response)\n",
    "cont_mult = tf.matmul(A_var, context)\n",
    "\n",
    "f = tf.nn.tanh(tf.matmul(tf.transpose(cont_mult), resp_mult))\n",
    "\n",
    "m = 0.01\n",
    "loss = tf.nn.relu(f_neg - f + m)\n",
    "\n",
    "LR = 0.001\n",
    "optimizer = tf.train.GradientDescentOptimizer(LR).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6024\n"
     ]
    }
   ],
   "source": [
    "print(len(vec_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10404c7cb5b43b3a5febe5bf3600d35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe398bf292141a5bf4118ac73a71ffa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 681.26000977]\n",
      "[array([[ 0.99286354]], dtype=float32)] [array([[ 0.30868417]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c07755cce954775a02629a6d10cec2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01037545] [ 261.6229248]\n",
      "[array([[ 0.99764019]], dtype=float32)] [array([[ 0.38179165]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f621476ff951472a80e359b683fabf1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01075728] [ 265.97769165]\n",
      "[array([[ 0.99864209]], dtype=float32)] [array([[ 0.42058]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1816c44d3dc4a1b810e434797a244ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01022298] [ 273.97573853]\n",
      "[array([[ 0.99906611]], dtype=float32)] [array([[ 0.44525474]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55763d34f42d4b32bd1e6b1cf5bd2c30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 277.25915527]\n",
      "[array([[ 0.9992978]], dtype=float32)] [array([[ 0.46429858]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff49a2baf0d4c009b34643d2e8e7324"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 279.20220947]\n",
      "[array([[ 0.99944097]], dtype=float32)] [array([[ 0.47857484]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7296054d02024cd08333eeab1c0aaf83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0096897] [ 279.83337402]\n",
      "[array([[ 0.99953592]], dtype=float32)] [array([[ 0.49092939]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966f3113e1af492dbc5a275fb673c048"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01022233] [ 282.09359741]\n",
      "[array([[ 0.9996047]], dtype=float32)] [array([[ 0.50150567]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af062e4326e466d9812229b35dfd0d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 283.96875]\n",
      "[array([[ 0.99965662]], dtype=float32)] [array([[ 0.51009864]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6da036dd10e42cfa5b8e01188852254"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 285.58453369]\n",
      "[array([[ 0.99969721]], dtype=float32)] [array([[ 0.51810676]], dtype=float32)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_vec_set = vec_set\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter('log/my_graph', sess.graph)\n",
    "avg_loss = 0.0\n",
    "for _ in tnrange(10):\n",
    "    for x, y in tqdm_notebook(train_vec_set):            \n",
    "        y_negs = random.sample(train_vec_set, 10)\n",
    "        for _, y_neg in y_negs:\n",
    "            f_neg_val = sess.run([f], feed_dict={context: x, response: y_neg})[0][0][0]\n",
    "            loss_val = sess.run([loss, optimizer], feed_dict={context: x, response: y, f_neg: f_neg_val})\n",
    "            avg_loss += loss_val[0][0]\n",
    "    print(loss_val[0][0], avg_loss)\n",
    "    avg_loss = 0\n",
    "    val_pos = sess.run([f], feed_dict={context: train_vec_set[-1][0], response: train_vec_set[-1][1]})\n",
    "    val_neg = sess.run([f], feed_dict={context: train_vec_set[-1][0], response: train_vec_set[100][1]})\n",
    "    print(val_pos, val_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.6867553]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "val = sess.run([f], feed_dict={context: train_vec_set[1][0], response: train_vec_set[3][1]})\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cache_vec = {}\n",
    "def best_response_emb(context_, candidates, session):\n",
    "    index = np.argmax([score_emb(context_, response_, session) for response_ in candidates])\n",
    "    return candidates[index]\n",
    "\n",
    "def score_emb(context_, response_, session):\n",
    "    if cache_vec.get(context_) is not None:\n",
    "        context_vec = cache_vec[context_]\n",
    "    else:\n",
    "        context_vec = build_vec(vocab_to_ind_map, context_)\n",
    "        cache_vec[context_] = context_vec\n",
    "    \n",
    "    if cache_vec.get(response_) is not None:\n",
    "        response_vec = cache_vec[response_]\n",
    "    else:\n",
    "        response_vec = build_vec(vocab_to_ind_map, response_)\n",
    "        cache_vec[response_] = response_vec\n",
    "        \n",
    "    val = session.run([f], feed_dict={context: context_vec, response: response_vec})[0][0][0]\n",
    "    return val\n",
    "\n",
    "def responses_accuracy_emb(dialogs, candidates, session):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for dialog in tqdm_notebook(dialogs):\n",
    "        for _, user_utt, bot_utt in dialog:\n",
    "            count += 1\n",
    "            context = user_utt\n",
    "            response = best_response_emb(context, candidates, session)\n",
    "            if response == bot_utt:\n",
    "                correct += 1\n",
    "    return correct / count, correct, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838d0ddf75dc40f2ab55c1ebf109ac38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4370739817123857, 2629, 6015)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_accuracy_emb(dev_set_task1_dialogs, candidates, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забывай подход с утилитами и кэшированием! (cat | grep | python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
